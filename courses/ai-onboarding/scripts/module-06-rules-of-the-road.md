# Module 6: Rules of the Road

**Duration:** 20-25 minutes  
**Part:** Two - Work With the Machine

---

## COLD OPEN

*[SCENE: A conference room. A mid-level manager — call him Kevin — is presenting quarterly projections to his leadership team. Slides look sharp. Numbers are clean. He's confident.]*

*[His director interrupts.]*

**DIRECTOR:** Kevin, where'd you get the 34% market growth figure?

**KEVIN:** I... pulled it from an industry report.

**DIRECTOR:** Which one?

*[Kevin hesitates. He doesn't remember. Because there was no report. The AI generated that number, and it looked right, and he didn't check.]*

*[The room goes quiet.]*

*[Beat.]*

**NARRATOR (V.O.):**  
Kevin didn't lie. He didn't cut corners on purpose. He trusted output that sounded authoritative, and he didn't verify it. And now his credibility is damaged in a room that matters.

This is the risk everyone warns you about — and almost nobody prepares you for. Knowing AI can hallucinate is easy. Catching it in the moment, when the output looks polished and you're in a hurry? That's the hard part.

*[TITLE CARD: "Rules of the Road"]*

---

## WHY THIS MODULE EXISTS

**NARRATOR (V.O.):**  
We've spent five modules teaching you how to get great output from AI. How to communicate clearly. How to have a conversation. How to build a context document that makes every interaction start from a higher baseline.

This module is about what can go wrong — and how to make sure it doesn't.

*[Beat.]*

**NARRATOR (V.O.):**  
Not because AI is dangerous. Not because you should be afraid of it. But because every powerful tool has failure modes, and a professional knows what they are before they matter. You learn to drive before you learn to brake — but you don't skip the braking.

---

## RULE ONE: VERIFY EVERYTHING THAT MATTERS

**NARRATOR (V.O.):**  
AI generates text that sounds confident. Always. It doesn't hedge when it's unsure. It doesn't flag when it's making something up. It presents everything — facts, figures, names, dates, citations — with the same smooth authority, whether it's right or wrong.

This is the single most important thing to understand about working with AI: **fluency is not accuracy.**

*[Beat.]*

**NARRATOR (V.O.):**  
The technical term is "hallucination." The machine generates something that sounds plausible but is factually wrong. A statistic that doesn't exist. A citation to a paper that was never published. A company policy that sounds reasonable but isn't your company's policy. A legal precedent that a lawyer would recognize as fabricated in two seconds.

It's not lying. It doesn't know what's true. It's generating the most statistically likely next sequence of words — and sometimes the most likely sequence happens to be wrong.

*[Beat.]*

*[VISUAL: A spectrum. On one end: "Low stakes — tone, structure, phrasing." On the other end: "High stakes — facts, numbers, legal, medical, financial."]*

**NARRATOR (V.O.):**  
Not everything needs the same level of verification. If the machine helps you draft an email and the tone is slightly off, you'll catch that in a read-through. Low stakes.

But if the output contains a number, a date, a name, a claim, a legal reference, a medical recommendation, or anything that someone might act on as fact — you verify. Every time. No exceptions.

*[Beat.]*

**NARRATOR (V.O.):**  
The rule is simple: **the higher the stakes, the harder you check.** AI is your drafting partner, not your fact-checker. Treat its output the way you'd treat a first draft from a smart intern who sometimes makes things up with complete confidence. You'd read it carefully, right? Do the same here.

---

## RULE TWO: KNOW WHAT IT CAN'T DO

**NARRATOR (V.O.):**  
AI is extraordinarily capable within its lane. It can draft, summarize, structure, brainstorm, analyze text, and organize information faster than any human.

It cannot do the following things, and you need to know that before you rely on it.

*[VISUAL: Building one at a time.]*

**NARRATOR (V.O.):**  
**It can't access real-time information.** Unless the specific tool you're using has web search enabled, the machine doesn't know what happened today. It doesn't know your stock price, the current weather, or whether your competitor just launched a new product. It knows what it was trained on — and that training has a cutoff date.

**It can't do math reliably.** It can set up equations, explain concepts, and write code that does math. But if you ask it to calculate something directly, it may get it wrong — especially with large numbers, percentages, or multi-step arithmetic. If the number matters, check it yourself or have it write code to compute it.

**It can't read your mind.** We covered this in Modules 3 and 4, but it bears repeating here. The machine works with what you give it. If you leave out critical context, the machine will fill the gap with its best guess. Sometimes that guess is right. Sometimes it's Kevin's 34% market growth figure.

**It can't know your company's specifics.** Unless you've given it your documentation — through a context document, uploaded files, or a configured knowledge base — the machine doesn't know your company's policies, your org chart, your pricing, your client history, or your internal processes. It will generate plausible-sounding versions of these things. They will often be wrong.

*[Beat.]*

**NARRATOR (V.O.):**  
None of these are reasons not to use AI. They're reasons to use it with eyes open. Every tool has limits. A calculator can't write a narrative. A spreadsheet can't hold a meeting. AI can't verify its own claims. Know the limits, work within them, and the tool stays powerful.

---

## RULE THREE: PROTECT WHAT'S PRIVATE

**NARRATOR (V.O.):**  
When you type something into an AI, where does it go?

*[Beat.]*

**NARRATOR (V.O.):**  
The honest answer is: it depends on which tool you're using, how your company has configured it, and what the provider's data policy says. And most people never check.

Here's what you need to know.

*[VISUAL: Simple, clear.]*

**NARRATOR (V.O.):**  
**Assume anything you type could be seen.** Not necessarily by a person — but by a system. Some AI providers use conversations to train future models. Some store conversations for a period of time. Some don't. The policies vary and they change.

The practical rule: **don't put anything into AI that you wouldn't put in an email to someone outside your company.**

*[Beat.]*

**NARRATOR (V.O.):**  
That means:

Client names and confidential details? Think twice. Can you anonymize it? "My client in the healthcare space" works just as well as the client's actual name for most tasks.

Internal financials? Strategy documents? Upcoming announcements? Don't paste them into a tool unless your IT team has approved it.

Personal information — employee records, social security numbers, medical information, customer data covered by privacy regulations? Never. Full stop.

*[Beat.]*

**NARRATOR (V.O.):**  
This isn't about fear. It's about professionalism. You wouldn't leave confidential documents on a table in a coffee shop. Treat AI inputs with the same basic judgment.

If your company has an AI usage policy, follow it. If they don't have one yet — and many don't — use the email test. If you wouldn't type it in an email to an outside vendor, don't type it into AI.

---

## RULE FOUR: YOU ARE RESPONSIBLE FOR THE OUTPUT

**NARRATOR (V.O.):**  
This is the rule that changes how you think about everything else.

*[Beat.]*

**NARRATOR (V.O.):**  
When you send an email that AI helped you write, your name is on it. When you present numbers that AI generated, you're the one standing in front of the room. When you submit a report, a proposal, a recommendation — it doesn't matter who drafted it. You signed off on it. You're accountable.

*[Beat.]*

**NARRATOR (V.O.):**  
AI doesn't have a reputation. You do. AI doesn't get fired for a bad recommendation. You might. AI doesn't lose a client's trust. You will.

This isn't a warning — it's a clarification. AI is a tool that works for you. The output is your responsibility the same way a document your assistant drafted is your responsibility. You review it. You approve it. You own it.

*[Beat.]*

**NARRATOR (V.O.):**  
And here's why this actually matters: this responsibility is what makes you valuable. The machine can produce a draft in seconds. What it can't do is decide whether that draft is right for this audience, this moment, this relationship. That judgment — the human judgment we've been building throughout this entire course — is your contribution. It's what you bring that the machine never will.

The person who reviews AI output carefully and catches the error that would have embarrassed the team? That person is indispensable. The person who hits send without reading because the AI "probably got it right"? That's Kevin.

Don't be Kevin.

---

## RULE FIVE: STAY CURRENT

**NARRATOR (V.O.):**  
One last rule, and it's the one that extends beyond this course.

*[Beat.]*

**NARRATOR (V.O.):**  
AI is changing. Fast. The tool you use today will have new capabilities next month. The things that don't work well now may work perfectly in six months. The limits we just discussed may shift. New risks may emerge that we can't predict yet.

*[Beat.]*

**NARRATOR (V.O.):**  
This doesn't mean you need to chase every update or read every AI newsletter. It means you need to stay curious. Pay attention to what your tools can do. Try new features when they appear. Talk to colleagues about what's working. Update your Working Context Document as your tools evolve.

The people who thrive with AI long-term are not the ones who mastered one version of one tool. They're the ones who developed the habit of learning continuously — not because they love technology, but because they understand that the tool keeps getting more powerful, and they want to use that power well.

*[Beat.]*

**NARRATOR (V.O.):**  
You've already started that habit. You're here. You've built the foundational skills. You've built a Working Context Document that makes your AI interactions smarter and faster. You know how to communicate, iterate, and evaluate. That foundation doesn't expire. What you've learned in this course will serve you regardless of which AI tool you're using a year from now — because the principles are human principles. Clear communication. Critical thinking. Good judgment. Knowing your own expertise and making it explicit.

The tools will change. Those skills won't.

---

## COURSE CLOSING

**NARRATOR (V.O.):**  
Let's take a step back and look at where you've been.

*[VISUAL: The six modules, appearing one at a time. A journey.]*

**NARRATOR (V.O.):**  
Module 1 — you learned what AI actually is. A pattern-matching machine. Powerful, but not magic.

Module 2 — you learned what it isn't. Not a search engine, not a mind reader, not a replacement for your judgment.

Module 3 — you learned that the gap between what you know and what you type is where most failures happen. Tacit knowledge has to become explicit.

Module 4 — you learned to communicate. Not to "prompt" — to have a conversation. Start clear, give feedback, iterate.

Module 5 — you built your playbook. A Working Context Document that makes every future interaction start from a foundation of who you are and how you work.

Module 6 — you learned the guardrails. Verify what matters, know the limits, protect what's private, own the output.

*[Beat.]*

**NARRATOR (V.O.):**  
That's the whole course. Not a bag of tricks. Not a list of templates. A fundamental shift in how you work with a tool that's going to be part of your professional life for the foreseeable future.

*[Beat.]*

**NARRATOR (V.O.):**  
You started this course as someone who probably typed a sentence into AI and hoped for the best. You're leaving it as someone who understands why that doesn't work — and who has the skills and the tools to do it right.

The Working Context Document you built in Module 5? Use it tomorrow. Use it every day. Update it. Let it grow. It's the most tangible proof that you've internalized what this course teaches: that the intelligence is yours, and the machine is just waiting for you to share it.

*[Beat.]*

**NARRATOR (V.O.):**  
Thanks for being here. Now go do the work.

*[END.]*

---

## MODULE 6 QUIZ

**Question 1:**  
Kevin's mistake with the 34% market growth figure was:  
- A) Using AI to generate slides  
- B) Presenting AI-generated data without verifying its accuracy  
- C) Not using a premium AI model  
- D) Sharing confidential information with AI  

**Correct Answer: B**

**Question 2:**  
"Fluency is not accuracy" means:  
- A) AI can't write in a professional tone  
- B) AI output always contains errors  
- C) AI presents everything with equal confidence regardless of whether it's factually correct  
- D) You need to rewrite everything AI produces  

**Correct Answer: C**

**Question 3:**  
Your company doesn't have an AI usage policy yet. You need to draft a competitive analysis and want to use AI to help structure it. Which approach is best?  
- A) Paste in all your internal strategy documents and competitor data for the most accurate output  
- B) Use anonymized information and general industry context, keeping specific client names and confidential financials out  
- C) Don't use AI at all until your company creates a formal policy  
- D) Only use AI for personal tasks, never for work  

**Correct Answer: B**

**Question 4 (Scenario):**  
AI helps you draft a client proposal that includes a claim about your company's on-time delivery rate. You don't remember the exact number. You should:  
- A) Send it — the AI probably used accurate training data  
- B) Delete the claim entirely to avoid any risk  
- C) Verify the number against your company's actual data before including it  
- D) Add a disclaimer that the number was generated by AI  

**Correct Answer: C**

---

## NOTES FOR PRODUCTION

**Cold open — Kevin:**
- Kevin is not a villain. He's a cautionary tale. He's competent, well-meaning, and made the most common mistake in AI adoption: trusting output without checking it. The audience should think "that could be me" not "what an idiot."
- The room going quiet is the key moment. Let it land. No narrator explanation needed — the silence tells the story.
- Kevin should look polished. Good slides, confident delivery. The failure is invisible until the question exposes it. That's the point.

**Five rules structure:**
- Five rules is intentional — matches the five sections of the Working Context Document. Gives the course a structural symmetry. But don't draw attention to it. Let it be felt, not pointed out.
- Each rule should feel like practical wisdom, not compliance training. The tone is "here's what you need to know" not "here's what you're not allowed to do."

**Rule 1 — Verify:**
- "Fluency is not accuracy" is the most important line in the module. It's the one concept that, if internalized, prevents the most common AI failures. Let it sit.
- The stakes spectrum (low → high) is practical and visual. It gives the audience a decision framework, not a blanket rule. "Not everything needs verification" prevents paranoia. "Numbers, facts, citations always do" prevents Kevin.
- The "smart intern who sometimes makes things up with complete confidence" framing is the right analogy. It's memorable and it calibrates expectations correctly.

**Rule 2 — Limitations:**
- Keep this factual. Not scary, just clear. "Here's what it can't do" is a service to the audience. They need to know so they don't discover it the hard way.
- The math limitation surprises people. Worth emphasizing briefly.
- "Every tool has limits" normalizes it. A calculator can't write. A spreadsheet can't hold a meeting. AI can't verify itself.

**Rule 3 — Privacy:**
- The "email test" is the takeaway. Simple, memorable, actionable. If you wouldn't type it in an email to an outside vendor, don't type it into AI.
- Don't turn this into a legal lecture. The audience needs judgment, not a policy document.
- Anonymization as a practical solution. "My client in the healthcare space" instead of the actual name. Show that privacy-conscious use doesn't require giving up functionality.

**Rule 4 — Responsibility:**
- "AI doesn't have a reputation. You do." — This is the line that makes it personal. Let it land.
- This rule reframes everything. It's not a restriction — it's a statement of value. The person who reviews carefully and catches errors is worth more than the person who produces faster but sends garbage.
- "Don't be Kevin." — End the rule with a callback to the cold open. Gets a smile, reinforces the point.

**Rule 5 — Stay current:**
- This is the bridge to the rest of their career with AI. The course ends, the learning doesn't.
- Don't make this overwhelming. "Stay curious" not "stay on top of everything." Pay attention. Try new features. Talk to colleagues. That's it.
- The close — "the tools will change, those skills won't" — ties back to the course thesis. Human skills (communication, judgment, tacit knowledge) are permanent. AI tools are temporary. They've built the permanent thing.

**Course closing:**
- Recap all six modules in under 90 seconds. Don't re-explain — just name what each one gave them. The audience should feel the progression.
- "You started as someone who typed a sentence and hoped for the best" — this should feel true, not insulting. They'll smile because they recognize the change.
- "Now go do the work" — end clean. No upsell, no teaser, no "and in our next course..." Just a clean landing. The course is done. They're equipped. Go.

**Pacing:**
- Cold open (Kevin): ~2 min
- Why this module exists: ~1 min
- Rule 1 — Verify: ~4 min
- Rule 2 — Limitations: ~4 min
- Rule 3 — Privacy: ~4 min
- Rule 4 — Responsibility: ~3 min
- Rule 5 — Stay current: ~3 min
- Course closing: ~2 min
- Target total: ~23 min (allow ±2 min)

**Tone throughout:**
- Sober but not heavy. This is the safety briefing, not a scare video. The audience should feel prepared, not anxious.
- The narrator's stance shifts one final time: from teacher to trusted advisor. "Here's what I want you to know before I send you off."
- The course closing should feel earned. Warm. Like the end of a good class where you actually learned something.
